{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "received-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import config\n",
    "\n",
    "sns.set()\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mechanical-universal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42962 entries, 0 to 42961\n",
      "Columns: 367 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(94), object(6)\n",
      "memory usage: 120.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('arvato-train.csv', sep=\";\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inclusive-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_cameo_features(data):\n",
    "    data['CAMEO_DEUG_2015'] = pd.to_numeric(data['CAMEO_DEUG_2015'], errors='coerce')\n",
    "    data['CAMEO_INTL_2015'] = pd.to_numeric(data['CAMEO_INTL_2015'], errors='coerce')\n",
    "    data['EINGEFUEGT_AM'] = pd.to_datetime(data['EINGEFUEGT_AM']).dt.year\n",
    "    data['CAMEO_DEU_2015'] = data['CAMEO_DEU_2015'].apply(lambda x: x[-1] if isinstance(x, str) else x)\n",
    "    return data\n",
    "\n",
    "def _core_replace_NaN(series):\n",
    "    \"\"\"\n",
    "    Replace negative and outliers values (according to the scale) to NaN. Takes a pd.Series as input\n",
    "    Works only on one column\n",
    "    \"\"\"\n",
    "    temp_unique = sorted(series.value_counts().index.tolist())\n",
    "    series = np.where(series < 0, np.nan, series)\n",
    "    if temp_unique[-1] - temp_unique[-2] > 1:\n",
    "        series = np.where(series == temp_unique[-1], np.nan, series)\n",
    "    return series\n",
    "\n",
    "def replace2NaN(data):\n",
    "    \"\"\"\n",
    "    Replace negative and outliers values for all columns in a Dataframe. Takes a pd.DataFrame as input\n",
    "    it returns the same dataframe with a summary of the percentage of null for each column to see which one\n",
    "    were affected.\n",
    "    \"\"\"\n",
    "    data= data.copy()\n",
    "    num_var = data.select_dtypes(include='number').columns.tolist()\n",
    "    \n",
    "    previous_state = data.isnull().mean()\n",
    "#     print(previous_state)\n",
    "    \n",
    "    for var in num_var:\n",
    "        data[var] = _core_replace_NaN(data[var])  \n",
    "        \n",
    "    after_state = data.isnull().mean()\n",
    "    \n",
    "    summary = pd.concat([previous_state.to_frame(), after_state.to_frame()], axis=1)\n",
    "    summary.columns = ['previous', 'after']\n",
    "    summary['difference'] = summary.diff(axis=1).after\n",
    "    cols_affected = (summary['difference'] > 0).sum()\n",
    "    \n",
    "    print(f'{cols_affected} columns were affected')\n",
    "    \n",
    "    return data, summary\n",
    "\n",
    "def remove_column_null(data, limit):\n",
    "    non_null_columns = [x for x in data.columns if data[x].isnull().mean() <= limit]\n",
    "    print(f'{len(non_null_columns)} out of {data.shape[1]} columns remains')\n",
    "    return data[non_null_columns], non_null_columns\n",
    "\n",
    "\n",
    "def remove_row_null(data, limit):\n",
    "    mask = data.isnull().sum(axis=1) <= limit\n",
    "    print(f'{mask.sum()} out of {data.shape[0]} rows remains')\n",
    "    return data[mask]\n",
    "\n",
    "def null_imputer(df, imputer):\n",
    "    return df.fillna(imputer)\n",
    "\n",
    "def one_hot_encoder(data):\n",
    "    data = pd.concat([data, pd.get_dummies(data['OST_WEST_KZ'], prefix='OST_WEST_KZ_')], axis=1).drop(columns=['OST_WEST_KZ'])\n",
    "    data = pd.concat([data, pd.get_dummies(data['CAMEO_DEU_2015'], prefix='CAMEO_DEU_2015_')], axis=1).drop(columns=['CAMEO_DEU_2015'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confident-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_pipeline(data, selected_columns, imputer, remove_null, limit_null_row=20, limit_null_column=0.2):\n",
    "    \n",
    "    data = data[selected_columns]\n",
    "    print('Fixing cameo columns')\n",
    "    data = fix_cameo_features(data)\n",
    "    print('Replacing value to NaN')\n",
    "    data, _ = replace2NaN(data)\n",
    "    if remove_null:\n",
    "        print(f'Removing columns with more than {limit_null_column}')\n",
    "        data, _ = remove_column_null(data, limit_null_column)\n",
    "        print(f'Removing rows with more than {limit_null_row}')\n",
    "        data = remove_row_null(data, limit_null_row)\n",
    "    print(f'Imputing null values')\n",
    "    data = null_imputer(data, imputer)\n",
    "    print('Encoding categorical columns')\n",
    "    data = one_hot_encoder(data)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adult-trinidad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing cameo columns\n",
      "Replacing value to NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-fac4531b9be8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEUG_2015'] = pd.to_numeric(data['CAMEO_DEUG_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_INTL_2015'] = pd.to_numeric(data['CAMEO_INTL_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['EINGEFUEGT_AM'] = pd.to_datetime(data['EINGEFUEGT_AM']).dt.year\n",
      "<ipython-input-6-fac4531b9be8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEU_2015'] = data['CAMEO_DEU_2015'].apply(lambda x: x[-1] if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 columns were affected\n",
      "Removing columns with more than 0.2\n",
      "271 out of 271 columns remains\n",
      "Removing rows with more than 20\n",
      "27773 out of 34369 rows remains\n",
      "Imputing null values\n",
      "Encoding categorical columns\n",
      "Fixing cameo columns\n",
      "Replacing value to NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-fac4531b9be8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEUG_2015'] = pd.to_numeric(data['CAMEO_DEUG_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_INTL_2015'] = pd.to_numeric(data['CAMEO_INTL_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['EINGEFUEGT_AM'] = pd.to_datetime(data['EINGEFUEGT_AM']).dt.year\n",
      "<ipython-input-6-fac4531b9be8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEU_2015'] = data['CAMEO_DEU_2015'].apply(lambda x: x[-1] if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 columns were affected\n",
      "Imputing null values\n",
      "Encoding categorical columns\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['RESPONSE']),\n",
    "                                                    data['RESPONSE'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=SEED\n",
    "                                                   )\n",
    "\n",
    "\n",
    "train = fe_pipeline(data=X_train, \n",
    "                    selected_columns=config.COLS_FINAL, \n",
    "                    remove_null=True,\n",
    "                   limit_null_column=0.2,\n",
    "                   limit_null_row=20,\n",
    "                   imputer = config.MODE_DICT)\n",
    "\n",
    "test = fe_pipeline(data=X_test, \n",
    "                    selected_columns=config.COLS_FINAL, \n",
    "                    remove_null=False,\n",
    "                   imputer = config.MODE_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sporting-finance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27773,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.loc[train.index.tolist()]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "breathing-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype('float')\n",
    "test = test.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pharmaceutical-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fit a model on X_train, y_train\n",
    "    predicts on X_text, y_test \n",
    "    Calculate AUROC on predictions made on test data\n",
    "    \n",
    "    Outputs - AUROC score, time elapse for training and prediction    \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    \n",
    "    return roc_score, time_elapsed\n",
    "\n",
    "models = [(\"LogisticRegression\", LogisticRegression(random_state=SEED, max_iter=10000)),\n",
    "         (\"RandomForestClassifier\", RandomForestClassifier(random_state=SEED)),\n",
    "         (\"GradientBoostingClassifier\", GradientBoostingClassifier(random_state=SEED)),\n",
    "         (\"AdaBoostClassifier\", AdaBoostClassifier(random_state=SEED)),\n",
    "          ('KNeighbors', KNeighborsClassifier()),\n",
    "         (\"XGBClassifier\",xgb.XGBClassifier(random_state=SEED))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-corpus",
   "metadata": {},
   "source": [
    "## Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "continuous-carnival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "GradientBoostingClassifier\n",
      "AdaBoostClassifier\n",
      "KNeighbors\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:48:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUCROC_score</th>\n",
       "      <th>Time_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.656398</td>\n",
       "      <td>41.289523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.634512</td>\n",
       "      <td>7.204932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.737012</td>\n",
       "      <td>33.795716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.684497</td>\n",
       "      <td>8.62734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.507838</td>\n",
       "      <td>6.664183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.683997</td>\n",
       "      <td>4.183281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model AUCROC_score Time_in_sec\n",
       "0          LogisticRegression     0.656398   41.289523\n",
       "1      RandomForestClassifier     0.634512    7.204932\n",
       "2  GradientBoostingClassifier     0.737012   33.795716\n",
       "3          AdaBoostClassifier     0.684497     8.62734\n",
       "4                  KNeighbors     0.507838    6.664183\n",
       "5               XGBClassifier     0.683997    4.183281"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "results = {\"Model\":[],\n",
    "          \"AUCROC_score\":[],\n",
    "          \"Time_in_sec\":[]}\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    roc, time_ = train_and_predict(model, train, y_train, test, y_test)\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"AUCROC_score\"].append(roc)\n",
    "    results[\"Time_in_sec\"].append(time_)\n",
    "\n",
    "    \n",
    "results = pd.DataFrame.from_dict(results, orient='index').transpose()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-baker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-block",
   "metadata": {},
   "source": [
    "### With Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ethical-ordinary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "GradientBoostingClassifier\n",
      "AdaBoostClassifier\n",
      "KNeighbors\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:49:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUCROC_score</th>\n",
       "      <th>Time_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.645132</td>\n",
       "      <td>2.404022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.63552</td>\n",
       "      <td>9.070027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.737012</td>\n",
       "      <td>33.050811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.684497</td>\n",
       "      <td>8.879995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.526006</td>\n",
       "      <td>6.24712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.683997</td>\n",
       "      <td>4.19005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model AUCROC_score Time_in_sec\n",
       "0          LogisticRegression     0.645132    2.404022\n",
       "1      RandomForestClassifier      0.63552    9.070027\n",
       "2  GradientBoostingClassifier     0.737012   33.050811\n",
       "3          AdaBoostClassifier     0.684497    8.879995\n",
       "4                  KNeighbors     0.526006     6.24712\n",
       "5               XGBClassifier     0.683997     4.19005"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "results = {\"Model\":[],\n",
    "          \"AUCROC_score\":[],\n",
    "          \"Time_in_sec\":[]}\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    roc, time_ = train_and_predict(model, train_scaled, y_train, test_scaled, y_test)\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"AUCROC_score\"].append(roc)\n",
    "    results[\"Time_in_sec\"].append(time_)\n",
    "\n",
    "    \n",
    "results = pd.DataFrame.from_dict(results, orient='index').transpose()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "falling-ottawa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   35.3s remaining:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.5s finished\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(best_model, train, y_train, scoring='roc_auc', n_jobs=-1, verbose=2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "prescription-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7636967803776888, 0.031072362995644615)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-crystal",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "missing-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:20:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgbclassifier = xgb.XGBClassifier(random_state=SEED)\n",
    "params = {\n",
    "    'learning_rate'    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'max_depth'        : [3,4,5,6,8,10,12,15],\n",
    "    'min_child_weight' : [1,3,5,7],\n",
    "    'gamma'            : [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'colsample_bytree' : [0.3, 0.4, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(xgbclassifier, param_distributions=params, n_iter=5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=3)\n",
    "random_search.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "loved-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "embedded-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7834846512733591"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "strategic-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:   28.3s remaining:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:   32.4s remaining:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   32.5s finished\n"
     ]
    }
   ],
   "source": [
    "best_xgb = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=42,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "cv = cross_val_score(best_xgb, train, y_train, scoring='roc_auc', n_jobs=-1, verbose=3, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "extreme-brass",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6913132418701566"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb = xgb.XGBClassifier(random_state=SEED, scale_pos_weight=10)\n",
    "best_xgb.fit(train, y_train)\n",
    "roc_score = roc_auc_score(y_test, best_xgb.predict_proba(test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "middle-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7760395599263137, 0.042949681523086564)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.mean(), cv.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-kennedy",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "automated-virtue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=12, min_samples_leaf=0.1,\n",
       "                           min_samples_split=0.8, n_estimators=64,\n",
       "                           random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate'    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'n_estimators'     : [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "    'max_depth'        : [3,4,5,6,8,10,12,15],\n",
    "    'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "    'min_samples_leaf' : np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=SEED)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=5)\n",
    "random_search.fit(train, y_train)\n",
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearch = GridSearchCV(model, param_grid=params, scoring='roc_auc', n_jobs=-1, cv=0, verbose=10)\n",
    "# gridsearch.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adapted-arrest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750184857849679"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score 0.80139\n",
    "model = GradientBoostingClassifier(learning_rate=0.15, max_depth=12,\n",
    "                           min_samples_leaf=0.2,\n",
    "                           min_samples_split=0.7000000000000001,\n",
    "                           n_estimators=16, random_state=42)\n",
    "model.fit(train, y_train)\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "killing-plane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score(y_test, model.predict(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "explicit-investment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7514813015553423"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score 0.8009\n",
    "model = GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=0.1,\n",
    "                           min_samples_split=0.7000000000000001,\n",
    "                           random_state=42)\n",
    "model.fit(train, y_train)\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-laptop",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "robust-strength",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "1    0.5\n",
       "Name: RESPONSE, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=SEED)\n",
    "X_sm, y_sm = sm.fit_resample(train, y_train)\n",
    "\n",
    "y_sm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "underlying-wells",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "GradientBoostingClassifier\n",
      "AdaBoostClassifier\n",
      "KNeighbors\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:56:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUCROC_score</th>\n",
       "      <th>Time_in_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.621517</td>\n",
       "      <td>123.101335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.64499</td>\n",
       "      <td>67.333851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.693575</td>\n",
       "      <td>193.411212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.663011</td>\n",
       "      <td>41.426377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.553883</td>\n",
       "      <td>26.166415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.665484</td>\n",
       "      <td>15.35159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model AUCROC_score Time_in_sec\n",
       "0          LogisticRegression     0.621517  123.101335\n",
       "1      RandomForestClassifier      0.64499   67.333851\n",
       "2  GradientBoostingClassifier     0.693575  193.411212\n",
       "3          AdaBoostClassifier     0.663011   41.426377\n",
       "4                  KNeighbors     0.553883   26.166415\n",
       "5               XGBClassifier     0.665484    15.35159"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = {\"Model\":[],\n",
    "          \"AUCROC_score\":[],\n",
    "          \"Time_in_sec\":[]}\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    roc, time_ = train_and_predict(model, X_sm, y_sm, test, y_test)\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"AUCROC_score\"].append(roc)\n",
    "    results[\"Time_in_sec\"].append(time_)\n",
    "\n",
    "    \n",
    "results = pd.DataFrame.from_dict(results, orient='index').transpose()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "colored-profile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7000596032433529, 0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(learning_rate=0.2, min_samples_leaf=0.1,\n",
    "                           min_samples_split=0.7000000000000001,\n",
    "                           random_state=42)\n",
    "model.fit(X_sm, y_sm)\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(test)[:,1])\n",
    "recall = recall_score(y_test, model.predict(test))\n",
    "roc_score, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "reflected-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "entire-increase",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.98591877109275,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.9929094638148257,\n",
       "  'support': 8472},\n",
       " '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 121},\n",
       " 'accuracy': 0.98591877109275,\n",
       " 'macro avg': {'precision': 0.492959385546375,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.49645473190741285,\n",
       "  'support': 8593},\n",
       " 'weighted avg': {'precision': 0.9720358231930382,\n",
       "  'recall': 0.98591877109275,\n",
       "  'f1-score': 0.9789280783706742,\n",
       "  'support': 8593}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, model.predict(test), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rolled-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-trial",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "strong-change",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = GradientBoostingClassifier(random_state=SEED)\n",
    "best_model.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "deadly-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "<ipython-input-6-fac4531b9be8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEUG_2015'] = pd.to_numeric(data['CAMEO_DEUG_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_INTL_2015'] = pd.to_numeric(data['CAMEO_INTL_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['EINGEFUEGT_AM'] = pd.to_datetime(data['EINGEFUEGT_AM']).dt.year\n",
      "<ipython-input-6-fac4531b9be8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEU_2015'] = data['CAMEO_DEU_2015'].apply(lambda x: x[-1] if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing cameo columns\n",
      "Replacing value to NaN\n",
      "12 columns were affected\n",
      "Imputing null values\n",
      "Encoding categorical columns\n"
     ]
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('arvato-test.csv', sep=';')\n",
    "mailout_test_clean = fe_pipeline(data=mailout_test, \n",
    "                    selected_columns=config.COLS_FINAL, \n",
    "                    remove_null=False,\n",
    "                   imputer = config.MODE_DICT)\n",
    "\n",
    "yhat = pd.DataFrame(model.predict_proba(mailout_test_clean)[:,1], index=mailout_test['LNR'], columns=['RESPONSE'])\n",
    "yhat.head()\n",
    "yhat.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-saver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
