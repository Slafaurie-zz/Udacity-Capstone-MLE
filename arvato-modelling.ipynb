{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alleged-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import config\n",
    "\n",
    "\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pretty-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train, test\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X_train, y_train = train.drop(columns=['TARGET']), train['TARGET']\n",
    "X_test, y_test = test.drop(columns=['TARGET']), test['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "increased-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fit a model on X_train, y_train\n",
    "    predicts on X_text, y_test \n",
    "    Calculate AUROC on predictions made on test data\n",
    "    \n",
    "    Outputs - AUROC score, time elapse for training and prediction    \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    cv = cross_val_score(model, X_train, y_train, scoring='roc_auc', n_jobs=-1, verbose=2, cv=5)\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    \n",
    "    return roc_score, time_elapsed, cv\n",
    "\n",
    "models = [(\"LogisticRegression\", LogisticRegression(random_state=SEED, max_iter=10000)),\n",
    "         (\"RandomForestClassifier\", RandomForestClassifier(random_state=SEED)),\n",
    "         (\"GradientBoostingClassifier\", GradientBoostingClassifier(random_state=SEED)),\n",
    "         (\"AdaBoostClassifier\", AdaBoostClassifier(random_state=SEED)),\n",
    "          ('KNeighbors', KNeighborsClassifier()),\n",
    "         (\"XGBClassifier\",xgb.XGBClassifier(random_state=SEED))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-halloween",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "unnecessary-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:  2.4min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    6.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   27.2s remaining:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    8.6s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   57.7s remaining:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:12:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   19.6s remaining:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUCROC_score</th>\n",
       "      <th>Time_in_sec</th>\n",
       "      <th>cv_mean</th>\n",
       "      <th>cv_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.656398</td>\n",
       "      <td>196.070127</td>\n",
       "      <td>0.640466</td>\n",
       "      <td>0.028124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.634512</td>\n",
       "      <td>13.217502</td>\n",
       "      <td>0.610521</td>\n",
       "      <td>0.018577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.737012</td>\n",
       "      <td>61.439194</td>\n",
       "      <td>0.763697</td>\n",
       "      <td>0.031072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.684497</td>\n",
       "      <td>19.411731</td>\n",
       "      <td>0.741957</td>\n",
       "      <td>0.024768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.507838</td>\n",
       "      <td>69.892156</td>\n",
       "      <td>0.504493</td>\n",
       "      <td>0.019561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.683997</td>\n",
       "      <td>24.337503</td>\n",
       "      <td>0.753749</td>\n",
       "      <td>0.021391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model AUCROC_score Time_in_sec   cv_mean    cv_std\n",
       "0          LogisticRegression     0.656398  196.070127  0.640466  0.028124\n",
       "1      RandomForestClassifier     0.634512   13.217502  0.610521  0.018577\n",
       "2  GradientBoostingClassifier     0.737012   61.439194  0.763697  0.031072\n",
       "3          AdaBoostClassifier     0.684497   19.411731  0.741957  0.024768\n",
       "4                  KNeighbors     0.507838   69.892156  0.504493  0.019561\n",
       "5               XGBClassifier     0.683997   24.337503  0.753749  0.021391"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "results = {\"Model\":[],\n",
    "          \"AUCROC_score\":[],\n",
    "          \"Time_in_sec\":[],\n",
    "          'cv_mean':[],\n",
    "          'cv_std':[]}\n",
    "\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    roc, time_, cv = train_and_predict(model, X_train, y_train, X_test, y_test)\n",
    "    results[\"Model\"].append(name)\n",
    "    results[\"AUCROC_score\"].append(roc)\n",
    "    results[\"Time_in_sec\"].append(time_)\n",
    "    results['cv_mean'].append(cv.mean())\n",
    "    results['cv_std'].append(cv.std())\n",
    "\n",
    "    \n",
    "results = pd.DataFrame.from_dict(results, orient='index').transpose()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-collective",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "parental-mention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_leaf=0.1,\n",
       "                           min_samples_split=0.9, n_estimators=64,\n",
       "                           random_state=42)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate'    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'n_estimators'     : [1, 2, 4, 8, 16, 32, 64, 100, 200],\n",
    "    'max_depth'        : [3,4,5,6,8,10,12,15],\n",
    "    'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "    'min_samples_leaf' : np.linspace(0.1, 0.5, 5, endpoint=True),\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=SEED)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=params, n_iter=5, scoring='roc_auc', n_jobs=-1, cv=5, verbose=5)\n",
    "random_search.fit(train, y_train)\n",
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "creative-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.750184857849679"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score 0.80139\n",
    "model = GradientBoostingClassifier(learning_rate=0.15, max_depth=12,\n",
    "                           min_samples_leaf=0.2,\n",
    "                           min_samples_split=0.7000000000000001,\n",
    "                           n_estimators=16, random_state=42)\n",
    "model.fit(train, y_train)\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "viral-nature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7501019400806935"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## score 0.80139\n",
    "model = GradientBoostingClassifier(learning_rate=0.2, max_depth=5, min_samples_leaf=0.1,\n",
    "                           min_samples_split=0.9, n_estimators=64,\n",
    "                           random_state=42)\n",
    "model.fit(train, y_train)\n",
    "roc_score = roc_auc_score(y_test, model.predict_proba(test)[:,1])\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-disposition",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fallen-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanl\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "<ipython-input-6-fac4531b9be8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEUG_2015'] = pd.to_numeric(data['CAMEO_DEUG_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_INTL_2015'] = pd.to_numeric(data['CAMEO_INTL_2015'], errors='coerce')\n",
      "<ipython-input-6-fac4531b9be8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['EINGEFUEGT_AM'] = pd.to_datetime(data['EINGEFUEGT_AM']).dt.year\n",
      "<ipython-input-6-fac4531b9be8>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['CAMEO_DEU_2015'] = data['CAMEO_DEU_2015'].apply(lambda x: x[-1] if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing cameo columns\n",
      "Replacing value to NaN\n",
      "12 columns were affected\n",
      "Imputing null values\n",
      "Encoding categorical columns\n"
     ]
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('arvato-test.csv', sep=';')\n",
    "mailout_test_clean = fe_pipeline(data=mailout_test, \n",
    "                    selected_columns=config.COLS_FINAL, \n",
    "                    remove_null=False,\n",
    "                   imputer = config.MODE_DICT)\n",
    "\n",
    "yhat = pd.DataFrame(model.predict_proba(mailout_test_clean)[:,1], index=mailout_test['LNR'], columns=['RESPONSE'])\n",
    "yhat.head()\n",
    "yhat.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
